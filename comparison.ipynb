{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# df = pd.read_csv(Path(\"../fsrs-benchmark/dataset/3.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "next_day_starts_at = 4\n",
    "timezone = \"Europe/Moscow\"\n",
    "\n",
    "df = pd.read_csv(\"../fsrs-optimizer/dataset/Main_27_04_2023_apkg/revlog.csv\")\n",
    "df[\"review_date\"] = pd.to_datetime(df[\"review_time\"] // 1000, unit=\"s\")\n",
    "df[\"review_date\"] = df[\"review_date\"].dt.tz_localize(\"UTC\").dt.tz_convert(timezone)\n",
    "df.drop(df[df[\"review_date\"].dt.year < 2006].index, inplace=True)\n",
    "df[\"real_days\"] = df[\"review_date\"] - timedelta(hours=int(next_day_starts_at))\n",
    "df[\"real_days\"] = pd.DatetimeIndex(\n",
    "    df[\"real_days\"].dt.floor(\"D\", ambiguous=\"infer\", nonexistent=\"shift_forward\")\n",
    ").to_julian_date()\n",
    "df[\"delta_t\"] = df.real_days.diff()\n",
    "df.fillna({\"delta_t\": 0}, inplace=True)\n",
    "df[\"i\"] = df.groupby(\"card_id\").cumcount() + 1\n",
    "df.loc[df[\"i\"] == 1, \"delta_t\"] = -1\n",
    "df.rename(columns={\"review_rating\": \"rating\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import accumulate\n",
    "\n",
    "\n",
    "def cum_concat(x):\n",
    "    return list(accumulate(x))\n",
    "\n",
    "\n",
    "t_history = df.groupby(\"card_id\", group_keys=False)[\"delta_t\"].apply(\n",
    "    lambda x: cum_concat([[i] for i in x])\n",
    ")\n",
    "r_history = df.groupby(\"card_id\", group_keys=False)[\"rating\"].apply(\n",
    "    lambda x: cum_concat([[i] for i in x])\n",
    ")\n",
    "df[\"r_history\"] = [\n",
    "    \",\".join(map(str, item[:-1])) for sublist in r_history for item in sublist\n",
    "]\n",
    "df[\"t_history\"] = [\n",
    "    \",\".join(map(str, item[:-1])) for sublist in t_history for item in sublist\n",
    "]\n",
    "df[\"y\"] = df[\"rating\"].map(lambda x: 1 if x > 1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[df[\"delta_t\"] != 0].copy()\n",
    "df[\"i\"] = df.groupby(\"card_id\").cumcount() + 1\n",
    "df[\"first_rating\"] = df[\"r_history\"].map(lambda x: x[0] if len(x) > 0 else \"\")\n",
    "short_term_df = df[df[\"i\"] == 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import root_mean_squared_error\n",
    "from fsrs_optimizer import power_forgetting_curve\n",
    "\n",
    "\n",
    "history_to_stability = dict()\n",
    "\n",
    "for r_history in short_term_df.r_history.value_counts().index:\n",
    "    group = (\n",
    "        short_term_df[short_term_df[\"r_history\"] == r_history]\n",
    "        .groupby(\"delta_t\")\n",
    "        .agg({\"y\": [\"mean\", \"count\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    delta_t = group[\"delta_t\"]\n",
    "    recall = group[\"y\"][\"mean\"]\n",
    "    count = group[\"y\"][\"count\"]\n",
    "    init_s0 = 1\n",
    "\n",
    "    def loss(stability):\n",
    "        y_pred = power_forgetting_curve(delta_t, stability)\n",
    "        logloss = sum(\n",
    "            -(recall * np.log(y_pred) + (1 - recall) * np.log(1 - y_pred)) * count\n",
    "        )\n",
    "        l1 = np.abs(stability - init_s0) / 16\n",
    "        return logloss + l1\n",
    "\n",
    "    res = minimize(\n",
    "        loss,\n",
    "        x0=init_s0,\n",
    "        bounds=((0.01, 300),),\n",
    "    )\n",
    "    params = res.x\n",
    "    stability = params[0]\n",
    "    predict_recall = power_forgetting_curve(delta_t, *params)\n",
    "    rmse = root_mean_squared_error(recall, predict_recall, sample_weight=count)\n",
    "    history_to_stability[r_history] = (round(stability, 2), count.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_to_stability = dict()\n",
    "\n",
    "for first_rating in short_term_df.first_rating.value_counts().index:\n",
    "    group = (\n",
    "        short_term_df[short_term_df[\"first_rating\"] == first_rating]\n",
    "        .groupby(\"delta_t\")\n",
    "        .agg({\"y\": [\"mean\", \"count\"]})\n",
    "        .reset_index()\n",
    "    )\n",
    "    delta_t = group[\"delta_t\"]\n",
    "    recall = group[\"y\"][\"mean\"]\n",
    "    count = group[\"y\"][\"count\"]\n",
    "    init_s0 = 1\n",
    "\n",
    "    def loss(stability):\n",
    "        y_pred = power_forgetting_curve(delta_t, stability)\n",
    "        logloss = sum(\n",
    "            -(recall * np.log(y_pred) + (1 - recall) * np.log(1 - y_pred)) * count\n",
    "        )\n",
    "        l1 = np.abs(stability - init_s0) / 16\n",
    "        return logloss + l1\n",
    "\n",
    "    res = minimize(\n",
    "        loss,\n",
    "        x0=init_s0,\n",
    "        bounds=((0.01, 300),),\n",
    "    )\n",
    "    params = res.x\n",
    "    stability = params[0]\n",
    "    predict_recall = power_forgetting_curve(delta_t, *params)\n",
    "    rmse = root_mean_squared_error(recall, predict_recall, sample_weight=count)\n",
    "    rating_to_stability[first_rating] = (round(stability, 2), count.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('2', (0.23, 7276))\n",
      "('2,2,3,3', (1.72, 133))\n",
      "('2,3', (1.48, 136))\n",
      "('2,3,3', (2.16, 435))\n",
      "('2,3,3,3', (9.01, 109))\n",
      "('3', (1.18, 13152))\n",
      "('3,2', (0.5, 279))\n",
      "('3,3', (2.18, 2080))\n",
      "('3,3,3', (15.55, 227))\n",
      "('3,4', (10.48, 154))\n",
      "('4', (181.33, 4570))\n",
      "-----------------\n",
      "('1', (0.5, 82))\n",
      "('2', (0.28, 8894))\n",
      "('3', (1.24, 16289))\n",
      "('4', (181.33, 4570))\n"
     ]
    }
   ],
   "source": [
    "stability = list(history_to_stability.items())\n",
    "stability = sorted(stability)\n",
    "threshold = sorted(stability, key=lambda x: x[1][1], reverse=True)[10][1][1]\n",
    "for i in range(len(stability)):\n",
    "    if stability[i][1][1] < threshold:\n",
    "        continue\n",
    "    print(stability[i])\n",
    "\n",
    "print(\"-----------------\")\n",
    "\n",
    "stability = list(rating_to_stability.items())\n",
    "stability = sorted(stability)\n",
    "for i in range(len(stability)):\n",
    "    print(stability[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "short_term_df = short_term_df[\n",
    "    short_term_df[\"r_history\"].isin(history_to_stability.keys())\n",
    "].copy()\n",
    "\n",
    "short_term_df[\"stability_by_history\"] = short_term_df[\"r_history\"].map(\n",
    "    lambda x: history_to_stability[x][0]\n",
    ")\n",
    "short_term_df[\"stability_by_rating\"] = short_term_df[\"first_rating\"].map(\n",
    "    lambda x: rating_to_stability[x][0]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.07260396358288007\n",
      "0.07315641369077919\n"
     ]
    }
   ],
   "source": [
    "from fsrs_optimizer import load_brier\n",
    "\n",
    "short_term_df[\"predict_recall_by_history\"] = power_forgetting_curve(\n",
    "    short_term_df[\"delta_t\"], short_term_df[\"stability_by_history\"]\n",
    ")\n",
    "short_term_df[\"predict_recall_by_rating\"] = power_forgetting_curve(\n",
    "    short_term_df[\"delta_t\"], short_term_df[\"stability_by_rating\"]\n",
    ")\n",
    "\n",
    "\n",
    "def rmse_bin(predictions, real, bins=20):\n",
    "    brier = load_brier(predictions, real, bins=bins)\n",
    "    bin_prediction_means = brier[\"detail\"][\"bin_prediction_means\"]\n",
    "    bin_correct_means = brier[\"detail\"][\"bin_correct_means\"]\n",
    "    bin_counts = brier[\"detail\"][\"bin_counts\"]\n",
    "    mask = bin_counts > 0\n",
    "\n",
    "    rmse = root_mean_squared_error(\n",
    "        bin_correct_means[mask],\n",
    "        bin_prediction_means[mask],\n",
    "        sample_weight=bin_counts[mask],\n",
    "    )\n",
    "    return rmse\n",
    "\n",
    "\n",
    "print(rmse_bin(short_term_df[\"predict_recall_by_history\"], short_term_df[\"y\"]))\n",
    "print(rmse_bin(short_term_df[\"predict_recall_by_rating\"], short_term_df[\"y\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4086080804792899\n",
      "0.42574583160823953\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import log_loss\n",
    "\n",
    "print(log_loss(short_term_df[\"y\"], short_term_df[\"predict_recall_by_history\"]))\n",
    "print(log_loss(short_term_df[\"y\"], short_term_df[\"predict_recall_by_rating\"]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fsrs4anki",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
